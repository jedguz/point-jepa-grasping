{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f1a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 1.13.1+cu117\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇣ Downloading gs://adlr2025-pointclouds/pretrain_pointjepa_epoch=499-step=40500.ckpt → checkpoints/pretrain_pointjepa_epoch=499-step=40500.ckpt\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "\n",
    "from scripts.checkpoint_utils          import fetch_checkpoint\n",
    "from scripts.checkpoint_utils          import load_pretrained_backbone\n",
    "\n",
    "local_dir = \"checkpoints\"\n",
    "bucket = \"adlr2025-pointclouds\"\n",
    "backbone_filename = \"pretrain_pointjepa_epoch=499-step=40500.ckpt\"\n",
    "\n",
    "bb_local = os.path.join(local_dir, backbone_filename)\n",
    "ckpt_path  = fetch_checkpoint(bucket, backbone_filename, bb_local)\n",
    "# load_pretrained_backbone(model, bb_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2745e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State dict keys:\n",
      "mask_token\n",
      "positional_encoding.0.weight\n",
      "positional_encoding.0.bias\n",
      "positional_encoding.2.weight\n",
      "positional_encoding.2.bias\n",
      "tokenizer.embedding.encoder.first_conv.0.weight\n",
      "tokenizer.embedding.encoder.first_conv.1.weight\n",
      "tokenizer.embedding.encoder.first_conv.1.bias\n",
      "tokenizer.embedding.encoder.first_conv.1.running_mean\n",
      "tokenizer.embedding.encoder.first_conv.1.running_var\n",
      "tokenizer.embedding.encoder.first_conv.1.num_batches_tracked\n",
      "tokenizer.embedding.encoder.first_conv.3.weight\n",
      "tokenizer.embedding.encoder.first_conv.3.bias\n",
      "tokenizer.embedding.encoder.second_conv.0.weight\n",
      "tokenizer.embedding.encoder.second_conv.1.weight\n",
      "tokenizer.embedding.encoder.second_conv.1.bias\n",
      "tokenizer.embedding.encoder.second_conv.1.running_mean\n",
      "tokenizer.embedding.encoder.second_conv.1.running_var\n",
      "tokenizer.embedding.encoder.second_conv.1.num_batches_tracked\n",
      "tokenizer.embedding.encoder.second_conv.3.weight\n",
      "tokenizer.embedding.encoder.second_conv.3.bias\n",
      "student.blocks.0.norm1.weight\n",
      "student.blocks.0.norm1.bias\n",
      "student.blocks.0.attn.qkv.weight\n",
      "student.blocks.0.attn.qkv.bias\n",
      "student.blocks.0.attn.proj.weight\n",
      "student.blocks.0.attn.proj.bias\n",
      "student.blocks.0.norm2.weight\n",
      "student.blocks.0.norm2.bias\n",
      "student.blocks.0.mlp.fc1.weight\n",
      "student.blocks.0.mlp.fc1.bias\n",
      "student.blocks.0.mlp.fc2.weight\n",
      "student.blocks.0.mlp.fc2.bias\n",
      "student.blocks.1.norm1.weight\n",
      "student.blocks.1.norm1.bias\n",
      "student.blocks.1.attn.qkv.weight\n",
      "student.blocks.1.attn.qkv.bias\n",
      "student.blocks.1.attn.proj.weight\n",
      "student.blocks.1.attn.proj.bias\n",
      "student.blocks.1.norm2.weight\n",
      "student.blocks.1.norm2.bias\n",
      "student.blocks.1.mlp.fc1.weight\n",
      "student.blocks.1.mlp.fc1.bias\n",
      "student.blocks.1.mlp.fc2.weight\n",
      "student.blocks.1.mlp.fc2.bias\n",
      "student.blocks.2.norm1.weight\n",
      "student.blocks.2.norm1.bias\n",
      "student.blocks.2.attn.qkv.weight\n",
      "student.blocks.2.attn.qkv.bias\n",
      "student.blocks.2.attn.proj.weight\n",
      "student.blocks.2.attn.proj.bias\n",
      "student.blocks.2.norm2.weight\n",
      "student.blocks.2.norm2.bias\n",
      "student.blocks.2.mlp.fc1.weight\n",
      "student.blocks.2.mlp.fc1.bias\n",
      "student.blocks.2.mlp.fc2.weight\n",
      "student.blocks.2.mlp.fc2.bias\n",
      "student.blocks.3.norm1.weight\n",
      "student.blocks.3.norm1.bias\n",
      "student.blocks.3.attn.qkv.weight\n",
      "student.blocks.3.attn.qkv.bias\n",
      "student.blocks.3.attn.proj.weight\n",
      "student.blocks.3.attn.proj.bias\n",
      "student.blocks.3.norm2.weight\n",
      "student.blocks.3.norm2.bias\n",
      "student.blocks.3.mlp.fc1.weight\n",
      "student.blocks.3.mlp.fc1.bias\n",
      "student.blocks.3.mlp.fc2.weight\n",
      "student.blocks.3.mlp.fc2.bias\n",
      "student.blocks.4.norm1.weight\n",
      "student.blocks.4.norm1.bias\n",
      "student.blocks.4.attn.qkv.weight\n",
      "student.blocks.4.attn.qkv.bias\n",
      "student.blocks.4.attn.proj.weight\n",
      "student.blocks.4.attn.proj.bias\n",
      "student.blocks.4.norm2.weight\n",
      "student.blocks.4.norm2.bias\n",
      "student.blocks.4.mlp.fc1.weight\n",
      "student.blocks.4.mlp.fc1.bias\n",
      "student.blocks.4.mlp.fc2.weight\n",
      "student.blocks.4.mlp.fc2.bias\n",
      "student.blocks.5.norm1.weight\n",
      "student.blocks.5.norm1.bias\n",
      "student.blocks.5.attn.qkv.weight\n",
      "student.blocks.5.attn.qkv.bias\n",
      "student.blocks.5.attn.proj.weight\n",
      "student.blocks.5.attn.proj.bias\n",
      "student.blocks.5.norm2.weight\n",
      "student.blocks.5.norm2.bias\n",
      "student.blocks.5.mlp.fc1.weight\n",
      "student.blocks.5.mlp.fc1.bias\n",
      "student.blocks.5.mlp.fc2.weight\n",
      "student.blocks.5.mlp.fc2.bias\n",
      "student.blocks.6.norm1.weight\n",
      "student.blocks.6.norm1.bias\n",
      "student.blocks.6.attn.qkv.weight\n",
      "student.blocks.6.attn.qkv.bias\n",
      "student.blocks.6.attn.proj.weight\n",
      "student.blocks.6.attn.proj.bias\n",
      "student.blocks.6.norm2.weight\n",
      "student.blocks.6.norm2.bias\n",
      "student.blocks.6.mlp.fc1.weight\n",
      "student.blocks.6.mlp.fc1.bias\n",
      "student.blocks.6.mlp.fc2.weight\n",
      "student.blocks.6.mlp.fc2.bias\n",
      "student.blocks.7.norm1.weight\n",
      "student.blocks.7.norm1.bias\n",
      "student.blocks.7.attn.qkv.weight\n",
      "student.blocks.7.attn.qkv.bias\n",
      "student.blocks.7.attn.proj.weight\n",
      "student.blocks.7.attn.proj.bias\n",
      "student.blocks.7.norm2.weight\n",
      "student.blocks.7.norm2.bias\n",
      "student.blocks.7.mlp.fc1.weight\n",
      "student.blocks.7.mlp.fc1.bias\n",
      "student.blocks.7.mlp.fc2.weight\n",
      "student.blocks.7.mlp.fc2.bias\n",
      "student.blocks.8.norm1.weight\n",
      "student.blocks.8.norm1.bias\n",
      "student.blocks.8.attn.qkv.weight\n",
      "student.blocks.8.attn.qkv.bias\n",
      "student.blocks.8.attn.proj.weight\n",
      "student.blocks.8.attn.proj.bias\n",
      "student.blocks.8.norm2.weight\n",
      "student.blocks.8.norm2.bias\n",
      "student.blocks.8.mlp.fc1.weight\n",
      "student.blocks.8.mlp.fc1.bias\n",
      "student.blocks.8.mlp.fc2.weight\n",
      "student.blocks.8.mlp.fc2.bias\n",
      "student.blocks.9.norm1.weight\n",
      "student.blocks.9.norm1.bias\n",
      "student.blocks.9.attn.qkv.weight\n",
      "student.blocks.9.attn.qkv.bias\n",
      "student.blocks.9.attn.proj.weight\n",
      "student.blocks.9.attn.proj.bias\n",
      "student.blocks.9.norm2.weight\n",
      "student.blocks.9.norm2.bias\n",
      "student.blocks.9.mlp.fc1.weight\n",
      "student.blocks.9.mlp.fc1.bias\n",
      "student.blocks.9.mlp.fc2.weight\n",
      "student.blocks.9.mlp.fc2.bias\n",
      "student.blocks.10.norm1.weight\n",
      "student.blocks.10.norm1.bias\n",
      "student.blocks.10.attn.qkv.weight\n",
      "student.blocks.10.attn.qkv.bias\n",
      "student.blocks.10.attn.proj.weight\n",
      "student.blocks.10.attn.proj.bias\n",
      "student.blocks.10.norm2.weight\n",
      "student.blocks.10.norm2.bias\n",
      "student.blocks.10.mlp.fc1.weight\n",
      "student.blocks.10.mlp.fc1.bias\n",
      "student.blocks.10.mlp.fc2.weight\n",
      "student.blocks.10.mlp.fc2.bias\n",
      "student.blocks.11.norm1.weight\n",
      "student.blocks.11.norm1.bias\n",
      "student.blocks.11.attn.qkv.weight\n",
      "student.blocks.11.attn.qkv.bias\n",
      "student.blocks.11.attn.proj.weight\n",
      "student.blocks.11.attn.proj.bias\n",
      "student.blocks.11.norm2.weight\n",
      "student.blocks.11.norm2.bias\n",
      "student.blocks.11.mlp.fc1.weight\n",
      "student.blocks.11.mlp.fc1.bias\n",
      "student.blocks.11.mlp.fc2.weight\n",
      "student.blocks.11.mlp.fc2.bias\n",
      "student.norm.weight\n",
      "student.norm.bias\n",
      "predictor.mask_token\n",
      "predictor.predictor_embed.weight\n",
      "predictor.predictor_embed.bias\n",
      "predictor.positional_encoding.0.weight\n",
      "predictor.positional_encoding.0.bias\n",
      "predictor.positional_encoding.2.weight\n",
      "predictor.positional_encoding.2.bias\n",
      "predictor.predictor_norm.weight\n",
      "predictor.predictor_norm.bias\n",
      "predictor.predictor_proj.weight\n",
      "predictor.predictor_proj.bias\n",
      "predictor.predictor.blocks.0.norm1.weight\n",
      "predictor.predictor.blocks.0.norm1.bias\n",
      "predictor.predictor.blocks.0.attn.qkv.weight\n",
      "predictor.predictor.blocks.0.attn.qkv.bias\n",
      "predictor.predictor.blocks.0.attn.proj.weight\n",
      "predictor.predictor.blocks.0.attn.proj.bias\n",
      "predictor.predictor.blocks.0.norm2.weight\n",
      "predictor.predictor.blocks.0.norm2.bias\n",
      "predictor.predictor.blocks.0.mlp.fc1.weight\n",
      "predictor.predictor.blocks.0.mlp.fc1.bias\n",
      "predictor.predictor.blocks.0.mlp.fc2.weight\n",
      "predictor.predictor.blocks.0.mlp.fc2.bias\n",
      "predictor.predictor.blocks.1.norm1.weight\n",
      "predictor.predictor.blocks.1.norm1.bias\n",
      "predictor.predictor.blocks.1.attn.qkv.weight\n",
      "predictor.predictor.blocks.1.attn.qkv.bias\n",
      "predictor.predictor.blocks.1.attn.proj.weight\n",
      "predictor.predictor.blocks.1.attn.proj.bias\n",
      "predictor.predictor.blocks.1.norm2.weight\n",
      "predictor.predictor.blocks.1.norm2.bias\n",
      "predictor.predictor.blocks.1.mlp.fc1.weight\n",
      "predictor.predictor.blocks.1.mlp.fc1.bias\n",
      "predictor.predictor.blocks.1.mlp.fc2.weight\n",
      "predictor.predictor.blocks.1.mlp.fc2.bias\n",
      "predictor.predictor.blocks.2.norm1.weight\n",
      "predictor.predictor.blocks.2.norm1.bias\n",
      "predictor.predictor.blocks.2.attn.qkv.weight\n",
      "predictor.predictor.blocks.2.attn.qkv.bias\n",
      "predictor.predictor.blocks.2.attn.proj.weight\n",
      "predictor.predictor.blocks.2.attn.proj.bias\n",
      "predictor.predictor.blocks.2.norm2.weight\n",
      "predictor.predictor.blocks.2.norm2.bias\n",
      "predictor.predictor.blocks.2.mlp.fc1.weight\n",
      "predictor.predictor.blocks.2.mlp.fc1.bias\n",
      "predictor.predictor.blocks.2.mlp.fc2.weight\n",
      "predictor.predictor.blocks.2.mlp.fc2.bias\n",
      "predictor.predictor.blocks.3.norm1.weight\n",
      "predictor.predictor.blocks.3.norm1.bias\n",
      "predictor.predictor.blocks.3.attn.qkv.weight\n",
      "predictor.predictor.blocks.3.attn.qkv.bias\n",
      "predictor.predictor.blocks.3.attn.proj.weight\n",
      "predictor.predictor.blocks.3.attn.proj.bias\n",
      "predictor.predictor.blocks.3.norm2.weight\n",
      "predictor.predictor.blocks.3.norm2.bias\n",
      "predictor.predictor.blocks.3.mlp.fc1.weight\n",
      "predictor.predictor.blocks.3.mlp.fc1.bias\n",
      "predictor.predictor.blocks.3.mlp.fc2.weight\n",
      "predictor.predictor.blocks.3.mlp.fc2.bias\n",
      "predictor.predictor.blocks.4.norm1.weight\n",
      "predictor.predictor.blocks.4.norm1.bias\n",
      "predictor.predictor.blocks.4.attn.qkv.weight\n",
      "predictor.predictor.blocks.4.attn.qkv.bias\n",
      "predictor.predictor.blocks.4.attn.proj.weight\n",
      "predictor.predictor.blocks.4.attn.proj.bias\n",
      "predictor.predictor.blocks.4.norm2.weight\n",
      "predictor.predictor.blocks.4.norm2.bias\n",
      "predictor.predictor.blocks.4.mlp.fc1.weight\n",
      "predictor.predictor.blocks.4.mlp.fc1.bias\n",
      "predictor.predictor.blocks.4.mlp.fc2.weight\n",
      "predictor.predictor.blocks.4.mlp.fc2.bias\n",
      "predictor.predictor.blocks.5.norm1.weight\n",
      "predictor.predictor.blocks.5.norm1.bias\n",
      "predictor.predictor.blocks.5.attn.qkv.weight\n",
      "predictor.predictor.blocks.5.attn.qkv.bias\n",
      "predictor.predictor.blocks.5.attn.proj.weight\n",
      "predictor.predictor.blocks.5.attn.proj.bias\n",
      "predictor.predictor.blocks.5.norm2.weight\n",
      "predictor.predictor.blocks.5.norm2.bias\n",
      "predictor.predictor.blocks.5.mlp.fc1.weight\n",
      "predictor.predictor.blocks.5.mlp.fc1.bias\n",
      "predictor.predictor.blocks.5.mlp.fc2.weight\n",
      "predictor.predictor.blocks.5.mlp.fc2.bias\n",
      "predictor.predictor.norm.weight\n",
      "predictor.predictor.norm.bias\n",
      "teacher.initted\n",
      "teacher.step\n",
      "teacher.online_model.blocks.0.norm1.weight\n",
      "teacher.online_model.blocks.0.norm1.bias\n",
      "teacher.online_model.blocks.0.attn.qkv.weight\n",
      "teacher.online_model.blocks.0.attn.qkv.bias\n",
      "teacher.online_model.blocks.0.attn.proj.weight\n",
      "teacher.online_model.blocks.0.attn.proj.bias\n",
      "teacher.online_model.blocks.0.norm2.weight\n",
      "teacher.online_model.blocks.0.norm2.bias\n",
      "teacher.online_model.blocks.0.mlp.fc1.weight\n",
      "teacher.online_model.blocks.0.mlp.fc1.bias\n",
      "teacher.online_model.blocks.0.mlp.fc2.weight\n",
      "teacher.online_model.blocks.0.mlp.fc2.bias\n",
      "teacher.online_model.blocks.1.norm1.weight\n",
      "teacher.online_model.blocks.1.norm1.bias\n",
      "teacher.online_model.blocks.1.attn.qkv.weight\n",
      "teacher.online_model.blocks.1.attn.qkv.bias\n",
      "teacher.online_model.blocks.1.attn.proj.weight\n",
      "teacher.online_model.blocks.1.attn.proj.bias\n",
      "teacher.online_model.blocks.1.norm2.weight\n",
      "teacher.online_model.blocks.1.norm2.bias\n",
      "teacher.online_model.blocks.1.mlp.fc1.weight\n",
      "teacher.online_model.blocks.1.mlp.fc1.bias\n",
      "teacher.online_model.blocks.1.mlp.fc2.weight\n",
      "teacher.online_model.blocks.1.mlp.fc2.bias\n",
      "teacher.online_model.blocks.2.norm1.weight\n",
      "teacher.online_model.blocks.2.norm1.bias\n",
      "teacher.online_model.blocks.2.attn.qkv.weight\n",
      "teacher.online_model.blocks.2.attn.qkv.bias\n",
      "teacher.online_model.blocks.2.attn.proj.weight\n",
      "teacher.online_model.blocks.2.attn.proj.bias\n",
      "teacher.online_model.blocks.2.norm2.weight\n",
      "teacher.online_model.blocks.2.norm2.bias\n",
      "teacher.online_model.blocks.2.mlp.fc1.weight\n",
      "teacher.online_model.blocks.2.mlp.fc1.bias\n",
      "teacher.online_model.blocks.2.mlp.fc2.weight\n",
      "teacher.online_model.blocks.2.mlp.fc2.bias\n",
      "teacher.online_model.blocks.3.norm1.weight\n",
      "teacher.online_model.blocks.3.norm1.bias\n",
      "teacher.online_model.blocks.3.attn.qkv.weight\n",
      "teacher.online_model.blocks.3.attn.qkv.bias\n",
      "teacher.online_model.blocks.3.attn.proj.weight\n",
      "teacher.online_model.blocks.3.attn.proj.bias\n",
      "teacher.online_model.blocks.3.norm2.weight\n",
      "teacher.online_model.blocks.3.norm2.bias\n",
      "teacher.online_model.blocks.3.mlp.fc1.weight\n",
      "teacher.online_model.blocks.3.mlp.fc1.bias\n",
      "teacher.online_model.blocks.3.mlp.fc2.weight\n",
      "teacher.online_model.blocks.3.mlp.fc2.bias\n",
      "teacher.online_model.blocks.4.norm1.weight\n",
      "teacher.online_model.blocks.4.norm1.bias\n",
      "teacher.online_model.blocks.4.attn.qkv.weight\n",
      "teacher.online_model.blocks.4.attn.qkv.bias\n",
      "teacher.online_model.blocks.4.attn.proj.weight\n",
      "teacher.online_model.blocks.4.attn.proj.bias\n",
      "teacher.online_model.blocks.4.norm2.weight\n",
      "teacher.online_model.blocks.4.norm2.bias\n",
      "teacher.online_model.blocks.4.mlp.fc1.weight\n",
      "teacher.online_model.blocks.4.mlp.fc1.bias\n",
      "teacher.online_model.blocks.4.mlp.fc2.weight\n",
      "teacher.online_model.blocks.4.mlp.fc2.bias\n",
      "teacher.online_model.blocks.5.norm1.weight\n",
      "teacher.online_model.blocks.5.norm1.bias\n",
      "teacher.online_model.blocks.5.attn.qkv.weight\n",
      "teacher.online_model.blocks.5.attn.qkv.bias\n",
      "teacher.online_model.blocks.5.attn.proj.weight\n",
      "teacher.online_model.blocks.5.attn.proj.bias\n",
      "teacher.online_model.blocks.5.norm2.weight\n",
      "teacher.online_model.blocks.5.norm2.bias\n",
      "teacher.online_model.blocks.5.mlp.fc1.weight\n",
      "teacher.online_model.blocks.5.mlp.fc1.bias\n",
      "teacher.online_model.blocks.5.mlp.fc2.weight\n",
      "teacher.online_model.blocks.5.mlp.fc2.bias\n",
      "teacher.online_model.blocks.6.norm1.weight\n",
      "teacher.online_model.blocks.6.norm1.bias\n",
      "teacher.online_model.blocks.6.attn.qkv.weight\n",
      "teacher.online_model.blocks.6.attn.qkv.bias\n",
      "teacher.online_model.blocks.6.attn.proj.weight\n",
      "teacher.online_model.blocks.6.attn.proj.bias\n",
      "teacher.online_model.blocks.6.norm2.weight\n",
      "teacher.online_model.blocks.6.norm2.bias\n",
      "teacher.online_model.blocks.6.mlp.fc1.weight\n",
      "teacher.online_model.blocks.6.mlp.fc1.bias\n",
      "teacher.online_model.blocks.6.mlp.fc2.weight\n",
      "teacher.online_model.blocks.6.mlp.fc2.bias\n",
      "teacher.online_model.blocks.7.norm1.weight\n",
      "teacher.online_model.blocks.7.norm1.bias\n",
      "teacher.online_model.blocks.7.attn.qkv.weight\n",
      "teacher.online_model.blocks.7.attn.qkv.bias\n",
      "teacher.online_model.blocks.7.attn.proj.weight\n",
      "teacher.online_model.blocks.7.attn.proj.bias\n",
      "teacher.online_model.blocks.7.norm2.weight\n",
      "teacher.online_model.blocks.7.norm2.bias\n",
      "teacher.online_model.blocks.7.mlp.fc1.weight\n",
      "teacher.online_model.blocks.7.mlp.fc1.bias\n",
      "teacher.online_model.blocks.7.mlp.fc2.weight\n",
      "teacher.online_model.blocks.7.mlp.fc2.bias\n",
      "teacher.online_model.blocks.8.norm1.weight\n",
      "teacher.online_model.blocks.8.norm1.bias\n",
      "teacher.online_model.blocks.8.attn.qkv.weight\n",
      "teacher.online_model.blocks.8.attn.qkv.bias\n",
      "teacher.online_model.blocks.8.attn.proj.weight\n",
      "teacher.online_model.blocks.8.attn.proj.bias\n",
      "teacher.online_model.blocks.8.norm2.weight\n",
      "teacher.online_model.blocks.8.norm2.bias\n",
      "teacher.online_model.blocks.8.mlp.fc1.weight\n",
      "teacher.online_model.blocks.8.mlp.fc1.bias\n",
      "teacher.online_model.blocks.8.mlp.fc2.weight\n",
      "teacher.online_model.blocks.8.mlp.fc2.bias\n",
      "teacher.online_model.blocks.9.norm1.weight\n",
      "teacher.online_model.blocks.9.norm1.bias\n",
      "teacher.online_model.blocks.9.attn.qkv.weight\n",
      "teacher.online_model.blocks.9.attn.qkv.bias\n",
      "teacher.online_model.blocks.9.attn.proj.weight\n",
      "teacher.online_model.blocks.9.attn.proj.bias\n",
      "teacher.online_model.blocks.9.norm2.weight\n",
      "teacher.online_model.blocks.9.norm2.bias\n",
      "teacher.online_model.blocks.9.mlp.fc1.weight\n",
      "teacher.online_model.blocks.9.mlp.fc1.bias\n",
      "teacher.online_model.blocks.9.mlp.fc2.weight\n",
      "teacher.online_model.blocks.9.mlp.fc2.bias\n",
      "teacher.online_model.blocks.10.norm1.weight\n",
      "teacher.online_model.blocks.10.norm1.bias\n",
      "teacher.online_model.blocks.10.attn.qkv.weight\n",
      "teacher.online_model.blocks.10.attn.qkv.bias\n",
      "teacher.online_model.blocks.10.attn.proj.weight\n",
      "teacher.online_model.blocks.10.attn.proj.bias\n",
      "teacher.online_model.blocks.10.norm2.weight\n",
      "teacher.online_model.blocks.10.norm2.bias\n",
      "teacher.online_model.blocks.10.mlp.fc1.weight\n",
      "teacher.online_model.blocks.10.mlp.fc1.bias\n",
      "teacher.online_model.blocks.10.mlp.fc2.weight\n",
      "teacher.online_model.blocks.10.mlp.fc2.bias\n",
      "teacher.online_model.blocks.11.norm1.weight\n",
      "teacher.online_model.blocks.11.norm1.bias\n",
      "teacher.online_model.blocks.11.attn.qkv.weight\n",
      "teacher.online_model.blocks.11.attn.qkv.bias\n",
      "teacher.online_model.blocks.11.attn.proj.weight\n",
      "teacher.online_model.blocks.11.attn.proj.bias\n",
      "teacher.online_model.blocks.11.norm2.weight\n",
      "teacher.online_model.blocks.11.norm2.bias\n",
      "teacher.online_model.blocks.11.mlp.fc1.weight\n",
      "teacher.online_model.blocks.11.mlp.fc1.bias\n",
      "teacher.online_model.blocks.11.mlp.fc2.weight\n",
      "teacher.online_model.blocks.11.mlp.fc2.bias\n",
      "teacher.online_model.norm.weight\n",
      "teacher.online_model.norm.bias\n",
      "teacher.ema_model.blocks.0.norm1.weight\n",
      "teacher.ema_model.blocks.0.norm1.bias\n",
      "teacher.ema_model.blocks.0.attn.qkv.weight\n",
      "teacher.ema_model.blocks.0.attn.qkv.bias\n",
      "teacher.ema_model.blocks.0.attn.proj.weight\n",
      "teacher.ema_model.blocks.0.attn.proj.bias\n",
      "teacher.ema_model.blocks.0.norm2.weight\n",
      "teacher.ema_model.blocks.0.norm2.bias\n",
      "teacher.ema_model.blocks.0.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.0.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.0.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.0.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.1.norm1.weight\n",
      "teacher.ema_model.blocks.1.norm1.bias\n",
      "teacher.ema_model.blocks.1.attn.qkv.weight\n",
      "teacher.ema_model.blocks.1.attn.qkv.bias\n",
      "teacher.ema_model.blocks.1.attn.proj.weight\n",
      "teacher.ema_model.blocks.1.attn.proj.bias\n",
      "teacher.ema_model.blocks.1.norm2.weight\n",
      "teacher.ema_model.blocks.1.norm2.bias\n",
      "teacher.ema_model.blocks.1.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.1.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.1.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.1.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.2.norm1.weight\n",
      "teacher.ema_model.blocks.2.norm1.bias\n",
      "teacher.ema_model.blocks.2.attn.qkv.weight\n",
      "teacher.ema_model.blocks.2.attn.qkv.bias\n",
      "teacher.ema_model.blocks.2.attn.proj.weight\n",
      "teacher.ema_model.blocks.2.attn.proj.bias\n",
      "teacher.ema_model.blocks.2.norm2.weight\n",
      "teacher.ema_model.blocks.2.norm2.bias\n",
      "teacher.ema_model.blocks.2.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.2.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.2.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.2.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.3.norm1.weight\n",
      "teacher.ema_model.blocks.3.norm1.bias\n",
      "teacher.ema_model.blocks.3.attn.qkv.weight\n",
      "teacher.ema_model.blocks.3.attn.qkv.bias\n",
      "teacher.ema_model.blocks.3.attn.proj.weight\n",
      "teacher.ema_model.blocks.3.attn.proj.bias\n",
      "teacher.ema_model.blocks.3.norm2.weight\n",
      "teacher.ema_model.blocks.3.norm2.bias\n",
      "teacher.ema_model.blocks.3.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.3.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.3.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.3.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.4.norm1.weight\n",
      "teacher.ema_model.blocks.4.norm1.bias\n",
      "teacher.ema_model.blocks.4.attn.qkv.weight\n",
      "teacher.ema_model.blocks.4.attn.qkv.bias\n",
      "teacher.ema_model.blocks.4.attn.proj.weight\n",
      "teacher.ema_model.blocks.4.attn.proj.bias\n",
      "teacher.ema_model.blocks.4.norm2.weight\n",
      "teacher.ema_model.blocks.4.norm2.bias\n",
      "teacher.ema_model.blocks.4.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.4.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.4.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.4.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.5.norm1.weight\n",
      "teacher.ema_model.blocks.5.norm1.bias\n",
      "teacher.ema_model.blocks.5.attn.qkv.weight\n",
      "teacher.ema_model.blocks.5.attn.qkv.bias\n",
      "teacher.ema_model.blocks.5.attn.proj.weight\n",
      "teacher.ema_model.blocks.5.attn.proj.bias\n",
      "teacher.ema_model.blocks.5.norm2.weight\n",
      "teacher.ema_model.blocks.5.norm2.bias\n",
      "teacher.ema_model.blocks.5.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.5.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.5.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.5.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.6.norm1.weight\n",
      "teacher.ema_model.blocks.6.norm1.bias\n",
      "teacher.ema_model.blocks.6.attn.qkv.weight\n",
      "teacher.ema_model.blocks.6.attn.qkv.bias\n",
      "teacher.ema_model.blocks.6.attn.proj.weight\n",
      "teacher.ema_model.blocks.6.attn.proj.bias\n",
      "teacher.ema_model.blocks.6.norm2.weight\n",
      "teacher.ema_model.blocks.6.norm2.bias\n",
      "teacher.ema_model.blocks.6.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.6.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.6.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.6.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.7.norm1.weight\n",
      "teacher.ema_model.blocks.7.norm1.bias\n",
      "teacher.ema_model.blocks.7.attn.qkv.weight\n",
      "teacher.ema_model.blocks.7.attn.qkv.bias\n",
      "teacher.ema_model.blocks.7.attn.proj.weight\n",
      "teacher.ema_model.blocks.7.attn.proj.bias\n",
      "teacher.ema_model.blocks.7.norm2.weight\n",
      "teacher.ema_model.blocks.7.norm2.bias\n",
      "teacher.ema_model.blocks.7.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.7.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.7.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.7.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.8.norm1.weight\n",
      "teacher.ema_model.blocks.8.norm1.bias\n",
      "teacher.ema_model.blocks.8.attn.qkv.weight\n",
      "teacher.ema_model.blocks.8.attn.qkv.bias\n",
      "teacher.ema_model.blocks.8.attn.proj.weight\n",
      "teacher.ema_model.blocks.8.attn.proj.bias\n",
      "teacher.ema_model.blocks.8.norm2.weight\n",
      "teacher.ema_model.blocks.8.norm2.bias\n",
      "teacher.ema_model.blocks.8.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.8.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.8.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.8.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.9.norm1.weight\n",
      "teacher.ema_model.blocks.9.norm1.bias\n",
      "teacher.ema_model.blocks.9.attn.qkv.weight\n",
      "teacher.ema_model.blocks.9.attn.qkv.bias\n",
      "teacher.ema_model.blocks.9.attn.proj.weight\n",
      "teacher.ema_model.blocks.9.attn.proj.bias\n",
      "teacher.ema_model.blocks.9.norm2.weight\n",
      "teacher.ema_model.blocks.9.norm2.bias\n",
      "teacher.ema_model.blocks.9.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.9.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.9.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.9.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.10.norm1.weight\n",
      "teacher.ema_model.blocks.10.norm1.bias\n",
      "teacher.ema_model.blocks.10.attn.qkv.weight\n",
      "teacher.ema_model.blocks.10.attn.qkv.bias\n",
      "teacher.ema_model.blocks.10.attn.proj.weight\n",
      "teacher.ema_model.blocks.10.attn.proj.bias\n",
      "teacher.ema_model.blocks.10.norm2.weight\n",
      "teacher.ema_model.blocks.10.norm2.bias\n",
      "teacher.ema_model.blocks.10.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.10.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.10.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.10.mlp.fc2.bias\n",
      "teacher.ema_model.blocks.11.norm1.weight\n",
      "teacher.ema_model.blocks.11.norm1.bias\n",
      "teacher.ema_model.blocks.11.attn.qkv.weight\n",
      "teacher.ema_model.blocks.11.attn.qkv.bias\n",
      "teacher.ema_model.blocks.11.attn.proj.weight\n",
      "teacher.ema_model.blocks.11.attn.proj.bias\n",
      "teacher.ema_model.blocks.11.norm2.weight\n",
      "teacher.ema_model.blocks.11.norm2.bias\n",
      "teacher.ema_model.blocks.11.mlp.fc1.weight\n",
      "teacher.ema_model.blocks.11.mlp.fc1.bias\n",
      "teacher.ema_model.blocks.11.mlp.fc2.weight\n",
      "teacher.ema_model.blocks.11.mlp.fc2.bias\n",
      "teacher.ema_model.norm.weight\n",
      "teacher.ema_model.norm.bias\n",
      "  • teacher\n",
      "  • positional_encoding\n",
      "  • student\n",
      "  • tokenizer\n",
      "  • predictor\n",
      "  • mask_token\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "state_dict = ckpt.get(\"state_dict\", None)\n",
    "if state_dict:\n",
    "    print(\"\\nState dict keys:\")\n",
    "    for k in state_dict.keys():\n",
    "        print(k)\n",
    "else:\n",
    "    print(\"No 'state_dict' key found. Might be a raw model checkpoint.\")\n",
    "\n",
    "top_keys = {k.split('.')[0] for k in state_dict.keys()}\n",
    "for key in top_keys:\n",
    "    print(f\"  • {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6acb44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(ckpt_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckpt)\n\u001b[1;32m      4\u001b[0m prefix_levels \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mset\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "prefix_levels = defaultdict(set)\n",
    "delimiter = '.'\n",
    "for key in state_dict.keys():\n",
    "    parts = key.split(delimiter)\n",
    "    for i in range(1, len(parts)):\n",
    "        prefix = delimiter.join(parts[:i])\n",
    "        prefix_levels[i].add(prefix)\n",
    "\n",
    "# Print prefixes per hierarchy level\n",
    "for level in sorted(prefix_levels.keys()):\n",
    "    print(f\"\\n🧩 Level {level} prefixes:\")\n",
    "    for prefix in sorted(prefix_levels[level]):\n",
    "        print(f\"  • {prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee583d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
