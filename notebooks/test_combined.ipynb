{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fdf1b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borispetrovic/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Both imports resolve!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "# sys.path.append(str(Path().resolve().parent / 'src'))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from models.encoders.jepa3d_wrapper import JEPA3DEncoderWrapper\n",
    "from ext.jepa3d.models.encoder_3djepa import Encoder3DJEPA\n",
    "from ext.point2vec.tokenizer import PointCloudTokenizer\n",
    "\n",
    "print(\"✅ Both imports resolve!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointcloud shape: torch.Size([2048, 3])\n",
      "Tokens shape: torch.Size([1, 2048, 1536])\n",
      "Centers shape: torch.Size([1, 2048, 3])\n",
      "Pointcloud statistics:\n",
      "  Mean: 0.0280\n",
      "  Std: 0.1147\n",
      "  Min: -0.3595\n",
      "  Max: 0.3609\n"
     ]
    }
   ],
   "source": [
    "# Load the point cloud data\n",
    "data = np.load('../data/pointclouds/02691156_1021a0914a7207aff927ed529ad90a11_2048.npz')\n",
    "pointcloud_np = data['points'] \n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "pointcloud_tensor = torch.from_numpy(pointcloud_np)\n",
    "print(f\"Pointcloud shape: {pointcloud_tensor.shape}\")\n",
    "\n",
    "# Get the p2v(point2vec) tokenizer features and centers\n",
    "# One group(patch) = one point, each with 1536 dimensional feature \n",
    "tokenizer = PointCloudTokenizer(2048, 1, None, 1536)\n",
    "tokens, centers = tokenizer(pointcloud_tensor.reshape(1, 2048, 3)) \n",
    "\n",
    "# Print some statistics about the tokenizer features and centers\n",
    "print(f\"Tokens shape: {tokens.shape}\")\n",
    "print(f\"Centers shape: {centers.shape}\")\n",
    "\n",
    "print(\"Pointcloud statistics:\")\n",
    "print(f\"  Mean: {centers.mean().item():.4f}\")\n",
    "print(f\"  Std: {centers.std().item():.4f}\")\n",
    "print(f\"  Min: {centers.min().item():.4f}\")\n",
    "print(f\"  Max: {centers.max().item():.4f}\")\n",
    "\n",
    "p2v_output = tokens.squeeze(0)\n",
    "p2v_positions = centers.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_featurized_scene_dict(p2v_output, p2v_positions, num_points=2048, device='cpu', model=None):\n",
    "    \"\"\"\n",
    "    Create a featurized scene dictionary that matches the expected input format\n",
    "    for the 3D-JEPA encoder based on the forward method.\n",
    "    \n",
    "    Args:\n",
    "        num_points: Number of points in the scene\n",
    "        device: Device to create tensors on\n",
    "        model: The model instance to check expected dimensions\n",
    "    \n",
    "    Returns:\n",
    "        dict: featurized_scene_dict with all required keys\n",
    "    \"\"\"\n",
    "    \n",
    "    floor_mask = torch.rand(num_points, device=device) < 0.3\n",
    "    ceiling_mask = (~floor_mask) & (torch.rand(num_points, device=device) < 0.2) \n",
    "    remaining_mask = ~floor_mask & ~ceiling_mask\n",
    "    \n",
    "    # Create RGB colors (0-1 range - model will multiply by 255)\n",
    "    rgb = torch.rand(num_points, 3, device=device) \n",
    "    rgb[floor_mask] = torch.tensor([0.4, 0.3, 0.2], device=device) + torch.rand((floor_mask.sum(), 3), device=device) * 0.3  \n",
    "    rgb[ceiling_mask] = torch.tensor([0.8, 0.8, 0.8], device=device) + torch.rand((ceiling_mask.sum(), 3), device=device) * 0.2\n",
    "    rgb = torch.clamp(rgb, 0, 1)\n",
    "    \n",
    "    # Create CLIP and DINO features with correct dimensions from the point2vec output\n",
    "    features_clip = p2v_output[:, :768].clone().detach().to(device)\n",
    "    features_dino = p2v_output[:, 768:].clone().detach().to(device)\n",
    "    \n",
    "    # Scale the shapenet object to the assumed expected scale by 3djepa\n",
    "    xyz = p2v_positions.clone().detach().to(device) * 7\n",
    "\n",
    "    # Create the featurized scene dictionary\n",
    "    featurized_scene_dict = {\n",
    "        \"features_clip\": features_clip,      # Shape: (num_points, clip_feat_dim)\n",
    "        \"features_dino\": features_dino,      # Shape: (num_points, dino_feat_dim)\n",
    "        \"rgb\": rgb,                          # Shape: (num_points, 3) in [0,1] range\n",
    "        \"points\": xyz,                       # Shape: (num_points, 3)\n",
    "    }\n",
    "    \n",
    "    return featurized_scene_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7d47498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] features.shape = torch.Size([1, 2048, 1536])\n",
      "[DEBUG] zero_token.shape = torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "# Import the pretrained 3djepa encoder \n",
    "model_3djepa = Encoder3DJEPA.from_pretrained(\"facebook/3d-jepa\")\n",
    "model_3djepa = model_3djepa.cuda()\n",
    "\n",
    "if hasattr(model_3djepa, 'zero_token'):\n",
    "    model_3djepa.zero_token = model_3djepa.zero_token.cuda()\n",
    "\n",
    "featurized_scene_dict = create_featurized_scene_dict(\n",
    "    p2v_output=p2v_output,\n",
    "    p2v_positions=p2v_positions,\n",
    "    num_points=2048, \n",
    "    model=model_3djepa,\n",
    "    device=torch.device('cuda')\n",
    ")\n",
    "\n",
    "output = model_3djepa(featurized_scene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10643863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output keys: dict_keys(['features', 'points'])\n",
      "Features shape: torch.Size([2048, 256])\n",
      "Points shape: torch.Size([2048, 3])\n",
      "Success! Generated embeddings from synthetic featurized scene.\n",
      "\n",
      "Feature statistics:\n",
      "  Mean: 0.0875\n",
      "  Std: 1.9679\n",
      "  Min: -12.3838\n",
      "  Max: 13.7755\n"
     ]
    }
   ],
   "source": [
    "# Analysis of the output od the 3Djepa encoder\n",
    "print(f\"Model output keys: {output.keys()}\")\n",
    "if 'features' in output:\n",
    "    print(f\"Features shape: {output['features'].shape}\")\n",
    "if 'points' in output:\n",
    "    print(f\"Points shape: {output['points'].shape}\")\n",
    "\n",
    "# Print some statistics about the output features\n",
    "if 'features' in output:\n",
    "    features = output['features']\n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"  Mean: {features.mean().item():.4f}\")\n",
    "    print(f\"  Std: {features.std().item():.4f}\")\n",
    "    print(f\"  Min: {features.min().item():.4f}\")\n",
    "    print(f\"  Max: {features.max().item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
